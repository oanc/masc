
  

  


  

    
      O_K. 
    
    
       O_K.   So the one - 
    
    
       one thing I knew I wanted to talk about was about, uh,
    
    
      sort of last minute stuff to- to, uh, try to get some recognition results.
    
    
      Recognition results  for -
    
    
      Yeah. 
    
    
      So, uh, on - on - on meeting data.
    
    
      
    
    
      And so, I'm - I'm not sure exactly what you're doing already, and - and there's some stuff I've talked to Dave -
    
    
      Well, we- I just started recognition on the
    
    
      on Thilo's  segments,
    
    
      which was - but using the far- far-
    
    
      
    
    
      the  close-talking  microphone.
    
    
      O_K. So -
    
    
      Um -
    
    
      And you wanted - I know you wanted the far-field  data.
    
    
      Right. So - so, we have  some  stuff with no overlap, uh, for which there would be
    
    
      near - near-field results.
    
    
      Uh-huh.
    
    
      We wanted to get the far-field results for that.
    
    
      And then this - this real, uh, long shot thing would be, that we'd apply Dave's processing
    
    
      to, uh, potentially training  and  test data
    
    
      Mm-hmm. 
    
    
      and do the - look at the same thing. And
    
    
      in talking this morning with, uh, Chuck and with Dave 
    
    
      one thought was to use - We couldn't remember how
    
    
      different the numbers were, but if you just  worked with males only and used the short training
    
    
      there're - there're - uh, I think Chuck's recollection was that when he was doing the feature stuff, it took maybe a day and a half
    
    
      to do the training. Yeah.
    
    
      To retrain?
    
    
      Uh 
    
    
      
    
    
      Yeah.
    
    
      Um.
    
    
      That's about right.
    
    
      
    
    
      Actually, it should probably be -
    
    
      It depends on who else is using machines, but we have more machines now. So.
    
    
      That's true. 
    
    
      It's more like a day, probably.
    
    
      Um, how much worse is the short training set than the large one, in terms of the ultimate performance?
    
    
      Mmm, it's like -
    
    
      Something like three - three percent -
    
    
      three or four percent absolute.
    
    
      Yep.
    
    
      So, it's - that should be fine for this, I would think.
    
    
      So we - an- and you have the short - you have short training results for
    
    
      the close  case?
    
    
      Um, not for meetings.
    
    
      Because we didn't train -
    
    
      we didn't re- ever recognize with the -
    
    
      with the
    
    
      small models  on meeting data.
    
    
      But I - I have the models, so I could
    
    
      So, how do you know it's - ? Oh, it's three percent on - on, uh, on Hub-five.
    
    
      run reco-
    
    
      On -
    
    
      Hub-five.
    
    
      I see.
    
    
      Yeah. But we have the models so we could get that number, and -
    
    
      So the question is, what - ?
    
    
       I mean, the - the - mmm- 
    
    
      w- 
    
    
      The recognition also takes  non-negligible amount of time. So -
    
    
      we might wanna restrict it to, maybe, a few meetings,
    
    
      if you want to do a full comparison.
    
    
      It has to be enough so that -
    
    
      Uh.
    
    
      I mean, it's the non-overlap only.
    
    
      Um - 
    
    
      And -
    
    
      it has to be enough to be  sort  of comparable to what
    
    
      you folks were seeing and what you reported already.
    
    
      Hmm.
    
    
      I mean -
    
    
      Well, do we have the - do we have the processed data? That - that's also -
    
    
      No. He has to create that.
    
    
      Right.
    
    
      But - but - s- but - so -
    
    
      Um -
    
    
      We have  a whole parallel set of things over here
    
    
      Mmm.
    
    
      which are all with digits.
    
    
      I see.
    
    
      And - and - and Dave has been working with that and there's all of those issues.
    
    
      But -
    
    
       I know that if I  go in with something that's not just digits it would be  good.
    
    
      And, um, so -
    
    
      We already have these results that you - I mean, on -
    
    
      uh, a l- a lot- tha- tha-
    
    
      a particular test set, that you - that we reported at H_L_T.
    
    
      Hmm.
    
    
      Right.
    
    
      Um, it'd be nice to have something  more  than that. And w- we had talked about was having distant -
    
    
      Um, and then,
    
    
      uh, if we could on top of that - I mean, so this is gonna be a lot worse. Right?
    
    
      Whatever comparison we - w- w- one would presume. But we don't know how  much  worse,
    
    
      Mm-hmm.
    
    
      Right.
    
    
      w- w- uh, which is certainly one interesting thing.
    
    
      And then, um,
    
    
      Dave - I think we figured that it'd probably take a day or two to compute the -
    
    
      the, uh -
    
    
      uh -
    
    
      
    
    
      Well -
    
    
      How many hours of training - ?
    
    
      
    
    
      Actually, I did retrain -
    
    
      I recently retrained,
    
    
      um, 
    
    
      for another reason, on the full training set.
    
    
      And that took only -
    
    
      I think it took only two days. 
    
    
      Yeah.
    
    
      So, it's actually conceivable
    
    
      to do - use the full training set.
    
    
      Yeah, but we also have to do this other processing, so having a smaller training set, if it's only a few percent difference, it might be -
    
    
      Oh, I see.
    
    
      be worth doing it.
    
    
       But- m-
    
    
      How big is the small  training  set?
    
    
      Do you remember?
    
    
      
    
    
      Hmm. 
    
    
       
    
    
      Uh.  Whew. 
    
    
      Hhh. 
    
    
      
    
    
      I don't know, something -
    
    
      something like -
    
    
      something  between   
    
    
      thirty and fifty hours, maybe. I f- I forget the
    
    
      It's around there.
    
    
      exac- Right.
    
    
      
    
    
      And ha- and - and male is roughly half of that, or - ?
    
    
      Or - or - or was that only male?
    
    
      Well, that's only male.
    
    
      
    
    
      Uh. Actually, I don't know.  I'd - 
    
    
      I - I can look it up.
    
    
      It's - it's - it's just, uh, I don't know the - remember the - the number.
    
    
      We could only jus- just do the male only right? Or
    
    
      O_K.
    
    
      Well, the males  account for most of this meeting data anyhow. So -
    
    
      will we run into trouble when we g- ?
    
    
      Yeah.
    
    
      Yeah. I would say we - you do only males.
    
    
      Yeah.
    
    
      So -
    
    
      
    
    
      Yeah. So that's certainly part of the issue, is that right now he's - he hasn't written his stuff for efficiency.
    
    
      Yeah. It's - it's in Matlab and so on, and -
    
    
      Mm-hmm.
    
    
      
    
    
      And, uh, it's not an  impossible  amount of time. We - we were
    
    
      guesstimating it was like one and a half times faster than real time, or something?
    
    
      So, if there's thirty hours of data, you can calculate
    
    
      u-
    
    
      that he can do, uh, the enhancement in
    
    
      a day
    
    
      and something. So -
    
    
      Hmm.
    
    
      But
    
    
      
    
    
       if  we were dealing with two hundred hours or something, I think it'd be  prohibitive.
    
    
      No. It's definitely -
    
    
      It's less than a hundred hours, for sure. It's -
    
    
      Yeah.
    
    
      It's probably actually, uh -
    
    
      It's - uh, I think it's around thirty hours
    
    
      just for -
    
    
      That's what I was thinking. Yeah.
    
    
      Yeah.
    
    
      for one gender. Yeah.
    
    
      
    
    
      Yeah. So, I mean, it's a bit of a push, but it seems like,
    
    
      O_K, we've got some models, we've got some training data, we have software that works, he's got
    
    
      a method that helps with, you know, other ta- another task.
    
    
      Um -
    
    
      It, you know,  appears  to be, you know, debugged.
    
    
      S-
    
    
      Mm-hmm.
    
    
      Um -
    
    
      So - We- Yo- So, one thing I was wondering is,
    
    
      did you already do that middle one or should
    
    
      we re-do that one, too?
    
    
      No. I didn't do that, because we haven't even
    
    
      You didn't do that. O_K.
    
    
      cut the waveforms for that. So -
    
    
      Yeah. That's what I was gonna say next. We hafta  cut the, uh -
    
    
      Right. So.
    
    
      W- s- so is - Morgan, is the plan to just pick one of the far-field mikes? Uh -
    
    
        Yeah.  
    
    
      
    
    
      And there's a bit of a question whether you want to use -
    
    
      Yes.
    
    
      um, what segmentations you want to use.
    
    
      Uh -
    
    
      Uh, David just -
    
    
      Um, I'm sorry.
    
    
       Don  just, uh, created
    
    
      a new
    
    
      version of the first meetings that we had previously recognized, but with different segmentation. And so -
    
    
      
    
    
      
    
    
      Um -
    
    
      It would be  nice  -
    
    
      I mean, if the results are  comparable   to what we had before -
    
    
      to use those segmentations, because
    
    
      th- then we could claim that everything's automatic.
    
    
      
    
    
      
    
    
      Do you know  when he'll have the - the comparison?
    
    
      Right.
    
    
      Well, I'm - as I said, I just started  the recognizer,
    
    
      um -
    
    
      It will -
    
    
      
    
    
      uh,  it will probably be  a couple hours before -
    
    
      before I have some results. So - 
    
    
      Oh. Well, that's not bad.
    
    
      Oh, O_K. So - cuz I don't think the new data
    
    
      will be ready, uh,
    
    
      for a couple days may- probably.
    
    
      You mean the training.
    
    
      So, the training.
    
    
      But the segmentations matter for the
    
    
      Yeah.
    
    
      filtering. Right? Because -
    
    
      For the  test. 
    
    
      For the test set. Yeah. So,
    
    
      Yeah, fo-
    
    
      Yeah.
    
    
      need to be - 
    
    
      But, first - first,
    
    
      of course, you would wanna process the  training data, because we wanna get that started. Yeah.
    
    
      Right.
    
    
      
    
    
      Yeah.
    
    
      I mean, it - it'd be really  great  if it was all automatic, but I think that, you know, given the pressure of time, if -
    
    
      i- i-
    
    
      I mean, since you're gonna find out in a short amount of time, that's great.
    
    
      Mm-hmm.
    
    
      But i- if - if it doesn't work out, I think we would rather charge ahead with the older
    
    
      Mm-hmm.
    
    
      segmentations and -
    
    
      Right.
    
    
      Um, and we were gonna use one of the P_Z_Ms.
    
    
      I don- I don't know what -
    
    
      Probably whatever one you've been using for - for - for the digits. Is it this one?
    
    
      I think it's that one. Right?
    
    
      It's e- F_.
    
    
      F_.
    
    
      Yeah, that's it.
    
    
      I - I'd - which - ? That's F_? How do you know?
    
    
      That's F_.
    
    
      
    
    
      It's the second nearest the machine room.
    
    
      
    
    
      Oh.
    
    
      
    
    
      
    
    
      
    
    
      
    
    
      
    
    
      
    
    
       Bien sur    O_K. 
    
    
      
    
    
      Alright, so -
    
    
      
    
    
      Bet they'll have fun with that one.
    
    
      O_K, so. 
    
    
      
    
    
      
    
    
      Uh - 
    
    
      O_K. So, uh, I just want to make sure I understand what we need to run.
    
    
      Um -
    
    
      Let's see. So, it's - O_K, so if we're talking about - Let's - let's assume that we're gonna use the new segmentations.
    
    
      We need to,
    
    
      um, 
    
    
      run recognition o- just looking at the no overlap column.
    
    
      Basically, we have to d- r- do recognitions for all three of those cases. Right?
    
    
      Mm-hmm. 
    
    
      Right.
    
    
      Um, because  we're gonna be using the - just the male,
    
    
      uh, model - short training set for the male. So we need to have results for all three of those, even though we have -
    
    
      Mm-hmm.
    
    
      Ma- maybe you should limit ourselves to the Meeting Recorder
    
    
      meetings?
    
    
      O_K.
    
    
      Um,
    
    
      if you were gonna cut down on the test set, I would suggest that.
    
    
      Well -
    
    
      Maybe. But, I - I mean, how long does it take
    
    
      
    
    
      Actually, the longer - the Robustness meetings take longer, because there's this one speaker who talks a lot.
    
    
      for the test?
    
    
      
    
    
      
    
    
      And so
    
    
      
    
    
      
    
    
      
    
    
      the -
    
    
      
    
    
      Um. No. It's because for all the -
    
    
      for the adaptation and normalization steps, you cannot -
    
    
      
    
    
      you have to d- you have to, uh, um, 
    
    
      you cannot chop it up into small pieces.
    
    
      So, you're sort of limited by how long the longest speaker,
    
    
      uh,
    
    
      is s- speaking.
    
    
      
    
    
      So how much data there is from the - the speaker who talks the most.
    
    
      
    
    
      So, 
    
    
      um, you parallelize across different  speakers, 
    
    
      Mm-hmm.
    
    
      but 
    
    
      you know, if you have a bunch of speakers who speak very little and then one wh-
    
    
      Right.
    
    
      who - who speaks a lot, then 
    
    
      effectively, everybody waits for the longest one to process. So.
    
    
      Right.
    
    
      Yeah.
    
    
       Bu-
    
    
      But what - what was your result for - uh, that we had at the H_L_T? Was that a combination of me?
    
    
      That was both types of meetings, but most - but there were only two Robustness meetings, and four or five,
    
    
      And if we're re-doing the baseline anyways, it - it - it would be O_K. Right? I mean -
    
    
      uh, Meeting Recorders.
    
    
      Right.
    
    
      To - to just limit ourselves to a smaller -
    
    
      How long would it take to run recognition, if we did that?
    
    
      Oh. 
    
    
      Uh, I - I -
    
    
      I don't have - I don't have a good  gue-
    
    
      I mean, is - is it like a  day  or is it  a few  hours  or - roughly?
    
    
      For everything? For all the meetings?
    
    
      For - yeah, let's say we  just  did the Meeting Recorder meetings for our test set.
    
    
      Uh. 
    
    
      Um. 
    
    
      It's probably more than a day, but probably less than two.
    
    
      Oh, really. I didn't realize each test took that long.
    
    
      Well, i- No. I mean for all the meetings.
    
    
      Because it's - 
    
    
      Again, it's, um -
    
    
      
    
    
       So each meeting - each meetings takes,
    
    
      So you were doing like -
    
    
      uh, something like -
    
    
      Again, we - we - I ran - when we ran these,
    
    
      we were sort of short on machines, and, um,
    
    
      Mmm.
    
    
      I don't know, I - I would estimate maybe four hours per meeting.
    
    
      Something like that.
    
    
      Four hours per meeting.
    
    
      Right.
    
    
      
    
    
      Wow. 
    
    
      Yeah. But if you -
    
    
      So, if you do half a dozen meetings, that's - that's about a day. We also have more machines now.
    
    
      Right.
    
    
       well  
    
    
      Right. So that's why I'm saying I'm not sure how they would scale with more machines.
    
    
      Yeah.
    
    
      Yeah.
    
    
      I mean, if we had about six - A six hour test set's not bad. Right?
    
    
      Right.
    
    
      
    
    
      
    
    
      S- six hour test set.
    
    
      Six meetings. O_K.
    
    
      You know?
    
    
      Right? I mean, a lot of the evaluations have been -
    
    
      Yeah. We did.
    
    
      We have M_R -
    
    
      two, th- We have two, three, four, fi- I think there are four Meeting Recorder meetings that we worked with.
    
    
      Four that you worked with?
    
    
      I think it's -
    
    
      Is it the same set as  the alignments? I think it's  five  Meeting Recorder meetings.
    
    
      Yeah.
    
    
      Five?
    
    
      O_K.
    
    
      That would be O_K, too. I mean, I'm -
    
    
      i- So, if they have a set that they worked with, and you - you got -
    
    
      
    
    
      
    
    
       
    
    
      Did you
    
    
      do similarly in performance between them and the other meetings, or was it - ?
    
    
      
    
    
      Uh, with the Robust- compared to Robustness?
    
    
      Yeah.
    
    
      The big variation is by - whether it's a native speaker
    
    
      Yeah.
    
    
      or not.
    
    
      And whether
    
    
      
    
    
      it's, um -
    
    
      Uh, I think that's the o- actually - and - and of course what,
    
    
      um,
    
    
      you know, whether it's lapel or,
    
    
      uh, headset microphone.
    
    
      And overlap or not. Yeah.
    
    
      Yeah.
    
    
       So maybe just with the - the - the Meeting Recorder set of the -
    
    
      And we can exclude - we don't need to recognize the  non-natives, because we know that -
    
    
      De- th- that you did before.
    
    
      I mean, in fact, we excluded them previously
    
    
      Yeah. So we want to do the same - same thing.
    
    
      from -
    
    
      Right.
    
    
      
    
    
      O_K. So - Alright. So if we got a list
    
    
      of the,
    
    
      uh, segmentations for these five Meeting Recorder meetings, we could start,
    
    
      uh, the first two
    
    
       experiments   going right away, using the short male models.
    
    
      Mm-hmm.
    
    
      So, you could get those going while
    
    
      Dave is, um, creating waveforms for the r- retraining the short male models.
    
    
      Yeah.
    
    
       Once we know which segmentations we're using. Yeah.
    
    
      Right. O_K. O_K. And then -
    
    
      O_K. So, do we w- also want to run
    
    
      that bottom experiment without
    
    
      retraining the short male models on his thing? Did you want that?
    
    
      Or - ?
    
    
      Um,
    
    
      I - I agree that that would be an interesting thing to do, but I sort of regard it as secondary.
    
    
      O_K. So, we'll save that.
    
    
      So if there's sort of machines sitting around and people sitting around and they're waiting for
    
    
      
    
    
      other things to finish, then sure. But -
    
    
      Uh, Chuck had been asking about that earlier as kind of a control to know, um -
    
    
      Cuz, I mean, you could imagine a fantasy in which you said that Dave's processing
    
    
      
    
    
      made the, uh, far microphone like the near microphone. In which case
    
    
      Mm-hmm.
    
    
      you shouldn't have to actually retrain.
    
    
      But it's - it's not really true. It's - it's sort of fantasy. It does - it does muck up the data in - in some funny ways. And so,
    
    
      Mm-hmm.
    
    
      
    
    
       I'm - I'm kind of questioning that. But -
    
    
      Well, i- it -
    
    
      But -
    
    
      Well, on a more basic level, also, it means that
    
    
      that  third  experiment, there are actually  two  differences between the other experiments, not one.
    
    
      Right.
    
    
      So, it's hard to know -
    
    
      It involves retraining and it involves a -
    
    
      Right.
    
    
      Uh, that's right.
    
    
      
    
    
      
    
    
      
    
    
      
    
    
      I mean the other thing which - which it might come in -
    
    
      to is if there was some  problem 
    
    
      in the retraining.
    
    
      I mean, maybe you'd just have some mechanical thing we do wrong.
    
    
      Mm-hmm.
    
    
      Uh, that, uh - since Dave's experience was that
    
    
      Right.
    
    
      it didn't help as  much  if you didn't retrain, but it does help some,
    
    
      that we would hopefully see that.
    
    
      Mm-hmm.
    
    
      So, that - that's - that's true.
    
    
       Wait, did - ?
    
    
      I- i-
    
    
      So when you used
    
    
      original - the original models, and you just process
    
    
      the test set in this way, d- do you get any -
    
    
      
    
    
       u- 
    
    
      do you get decent performance or not?
    
    
      I - I - I think, um,
    
    
      for the far-mike H_T_K system I was using,
    
    
      Mm-hmm.
    
    
      it did help somewhat. I could re-check that. But it was such a bad baseline
    
    
      Mmm.
    
    
      that
    
    
      I don't know what that means.
    
    
      Right.
    
    
      Right.
    
    
      O_K.
    
    
      Cuz the baseline word error rate was around forty percent on digits.
    
    
      Mm-hmm.
    
    
      On the far-field?
    
    
      Right.
    
    
      Right.
    
    
       So -
    
    
       O_K. Well, I'll - I can get started on the -
    
    
      well, the first -
    
    
      the one that already has a
    
    
      
    
    
      cross there. We need to re-do that with small models.
    
    
      Right.
    
    
      Yeah.
    
    
      And then, have to ask, um,
    
    
      I guess, Don
    
    
      to, uh, cut the,
    
    
      um,
    
    
      cut the segments for the sh-
    
    
      for the tis- distant mike.
    
    
      Uh, uh - that's - 
    
    
      So we would be using the  same  channel
    
    
      for each - fo- for everything?
    
    
      Mm-hmm.
    
    
      Yeah.
    
    
      O_K.
    
    
       I mean, do you ha- do you have to rely on his segmentations at all to do the top one?
    
    
      So.
    
    
      No, no. We would use the same segmentations, but he needs to extract -
    
    
      extract the wavef- form segments from a different channel.
    
    
      Oh. O_K.
    
    
      Got it.
    
    
      Right.
    
    
      So when you said you were gonna start that top one, were you gonna use the new segmentations?
    
    
      Mm-hmm.
    
    
      
    
    
      Um -
    
    
      Yeah.
    
    
      O_K.
    
    
      If - assuming that
    
    
      the performance
    
    
      turns out to be  comparable   with -
    
    
      with the old experiments
    
    
      Right. O_K.
    
    
      and the old segmentations.
    
    
      
    
    
      Now there's the issue of -
    
    
      
    
    
      Oh, O_K. So there's the issue of speaker normalization. So,
    
    
      with the distant microphone you wouldn't know which speaker
    
    
      is talking.
    
    
      Right?
    
    
      Can we - ?
    
    
      
    
    
      We - we talked about this before.
    
    
      I think what we were saying was that, um,
    
    
      the very fact that in both cases we're ignoring the overlap section
    
    
      means that, um,
    
    
      uh,
    
    
      we're to some extent finessing that. So,
    
    
      um, I think,
    
    
      for the purposes of  just  determining whether a far-field microphone -
    
    
      uh, what the effect of the far-field microphone is, we should do the same to both.
    
    
      Mm-hmm.
    
    
      I see. So you want to cheat?
    
    
      I mean - 
    
    
      
    
    
      
    
    
      
    
    
      
    
    
      
    
    
      
    
    
      
    
    
      We want to i- incorporate  
    
    
      
    
    
      
    
    
      
    
    
      certain data that would not be available during final tests, 
    
    
      
    
    
      
    
    
      uh, under a - a full fair test of it, much as we are in the - all the numbers that we have so far.  
    
    
      O_K. So we assume - we assume knowledge of the speakers as -
    
    
      
    
    
      
    
    
      Oops. 
    
    
      as, um - 
    
    
      in a way that's compatible with the close-talking
    
    
      Yeah.
    
    
      test set. O_K.
    
    
      We - we simply wanna determine what's the difference in performance due to being distant versus close.
    
    
      Oh, O_K.
    
    
      So,
    
    
      does that mean you turn off speaker normalization when you run it? Or you just let it do what it would do, an- ?
    
    
      No. It means - No. It just means
    
    
      
    
    
      you - you group together
    
    
      the segments  that by magic you know belong
    
    
      to one speaker,
    
    
      and - and treat -
    
    
      I mean to a lesser extent you had that same magic the other way, too, because
    
    
      you have leakage into other microphones. Right?
    
    
      But, it's just you're using the fact that
    
    
      
    
    
      Right.
    
    
      this is
    
    
      where this person is. Right?
    
    
      Right. 
    
    
      So.
    
    
      But, um -
    
    
      
    
    
      It's just easier to do.
    
    
      Well, in the new test, actually, that's not true.
    
    
      So - 
    
    
      Again, if this - if these new segmentations work O_K,
    
    
      Yeah.
    
    
      then we - then it's a fair -
    
    
      it's a completely fair  test.
    
    
      So, how do you determine what you use to group together to be a - a - ?
    
    
      You group together all the data coming in through one channel
    
    
      and where  Thilo's speech detector has -
    
    
      has determined that there is speech.
    
    
      
    
    
      And that speech is - is deemed to  come  from that speaker, whether that's true or not.
    
    
      So if you get some cross-talk from another microphone, then you just
    
    
      process this - it as if it were from that speaker.
    
    
      
    
    
      The only other alternative would be to turn off speaker adaptation in both.
    
    
      Well, that's more of a problem.
    
    
      
    
    
      I mean, because it's - You can just pretend it's some kind of
    
    
      gene- I mean you can  pretend  it's all from one speaker and do all this processing the same,
    
    
      but then you're gonna get results that are worse on account of not doing proper
    
    
      Mm-hmm. 
    
    
      speaker normalization and you're gonna have -
    
    
      So, you could certainly do  better  than that by doing, for instance - uh, cluster the segments,
    
    
      which is what we do, say, in a Broadcast News system, where you don't  have  speaker labels.
    
    
      But that would be another processing step that
    
    
      I'm - I would have to  debug first, and so forth, and so we wanna  avoid  that.
    
    
      Hmm.  
    
    
      So I agree with you. We should -
    
    
      
    
    
      we should, uh, do the -
    
    
      you know, this sort of cheating experiment.
    
    
      O_K.
    
    
      Yeah. An- and e- so that will tell us  what the difference it between the mikes, and then, uh, in order to -
    
    
      The - the other
    
    
      difference that we'd have to take care of is that, uh - yeah, we - we don't have  a  mike that, uh,
    
    
      is particular to a  person.  And so we'll have to do some clustering, and that'll be another -
    
    
      
    
    
      another, uh, issue, too.
    
    
      Mm-hmm.
    
    
      But, it - it - I could be wrong, but it seems to me that - that
    
    
      the speaker - the -
    
    
      the level of degradation that you get
    
    
      from
    
    
      having the distant mike in a normal acoustic
    
    
      Hmm.
    
    
      is much greater than what you get from, say, not applying speaker adaptation or applying speaker adaptation.
    
    
      I think that the -
    
    
      
    
    
      I mean, we'll see. But - but, I think that the kind of gains that we've seen from speaker adaptation
    
    
      
    
    
      on Hub-five sort of things are like a few percent. Right? And -
    
    
      
    
    
      It's not just speaker adaptation. It's the whole
    
    
      norm- feature normalization process. I- it's spea- uh, all that is speaker-based. 
    
    
      You know, so we -
    
    
      So, in  that  I'm,
    
    
      um -
    
    
      Y- you know, d- d- b- the most important, of course, is the  cepstral mean subtraction.
    
    
      
    
    
      And that -
    
    
      Yeah.
    
    
      I don't know if we - we never really - I don't remember,
    
    
      
    
    
      because it's so far - 
    
    
      s- so long ago that we didn't do that on a per speaker basis, but -
    
    
      It doesn't make that much difference, I think. I would doubt that it would be a huge amount of difference for that.
    
    
      So, I mean, I - I think that  that  difference would definitely be marginal.
    
    
      
    
    
      I think the  main  thing is to do  something  - to do some cepstral mean subtraction on some level.
    
    
      And, uh, so what's different about this processing is just that we're doing it
    
    
      at a much longer time  scale. Right?
    
    
      Hmm.
    
    
      Mmm.
    
    
      But -
    
    
      Um -
    
    
      
    
    
      A- and by the way, 
    
    
      What wo-
    
    
      it's - actually we're -
    
    
      
    
    
      we're already - If we use the same segmentations that we use for the close-talking microphone, then 
    
    
      the segmentations  assume  that we have access to all channels and
    
    
      cross
    
    
      That's right.
    
    
      correlate them, so 
    
    
      there's no  point  in not using that knowledge for speaker identification.
    
    
      Yeah.
    
    
      Mm-hmm.
    
    
      Uh, I- I think also for the log spectral mean subtraction,
    
    
      Yeah.
    
    
      uh, we wanna know which speaker's talking when, cuz we wanna
    
    
      chain together the audio from one particular speaker to calculate the mean and subtract it, and we don't -
    
    
      Yeah.
    
    
      Right.
    
    
      Right.
    
    
      O_K.
    
    
       Um. Yeah, I guess.
    
    
      But, um,
    
    
      
    
    
      I also think that a- again once we got into it, that, um, using some kind of clustering would probably
    
    
      work reasonably well there, too.
    
    
      Certainly for the - the two microphone case, which we're not gonna mess with because it's another whole
    
    
      deal with the low-quality microphones, um,
    
    
      we ought to be able to at least tell
    
    
      that it  appears  that things are coming from a particular direction.
    
    
      Hmm. 
    
    
      So we ought to be able to use  that  information,
    
    
      um, as well.
    
    
      But, I think we might
    
    
      be able to do not too bad a job of
    
    
      separating out
    
    
      sp-
    
    
      uh, segments that appear to come from a single speaker
    
    
      both in terms of s- acoustic similarity and in terms of direction.
    
    
      So, I mean - But that's another research thing to do and  probably won't get done the next week.
    
    
      
    
    
      
    
    
       Right. So what - what is the schedule here?
    
    
      
    
    
      
    
    
      Well, I mean, I'm - I'm leaving for  for the, uh,
    
    
      the New Orleans meeting, uh, next  Saturday,  and -
    
    
      Mm-hmm.
    
    
      and, um,  it'd be kinda nice to have
    
    
      
    
    
      some results at least a day or two before that, so that I could
    
    
      Mm-hmm.
    
    
      
    
    
      figure out what I wanted to say about it.
    
    
      Oh, we'll call you when you get there.
    
    
      
    
    
      
    
    
      
    
    
      
    
    
      
    
    
      
    
    
      You'll have email. Right?
    
    
      Yeah. 
    
    
      
    
    
      Uh, not to mention that - that, uh, Mari's putting together this report
    
    
      
    
    
      
    
    
      Mmm. 
    
    
      next week, too, you know. So -
    
    
      Uh,
    
    
      what we were  hoping  was that over the weekend we could do, uh, the, um, calculation on the training set
    
    
      Mmm.
    
    
      and, uh -
    
    
      uh, maybe, you know, we could -
    
    
      by the end of the weekend, we could have the top one, and - and then
    
    
      
    
    
      early next week, do these.
    
    
      Mmm.
    
    
      If we had enough machines, maybe do  them   in parallel.
    
    
      Mm-hmm.
    
    
      So that by the middle of the week we had s- had some kind of result.
    
    
      I mean, it's - it's one of these  Hail Mary kinds of things. I mean, it -
    
    
      
    
    
      it, uh -
    
    
      Mmm. 
    
    
      might - might not  work out.
    
    
      But, uh, f- figured I may as well ask for it.
    
    
      O_K.
    
    
      
    
    
      
    
    
      I'll ask -
    
    
      So - ?
    
    
      The other thing is, um -
    
    
      and I'll ask Don which is easier to process in terms of creating these -
    
    
      the - the test data for the far -
    
    
      far microphone.
    
    
      If - if it turns out that for some reason it's easier for him to 
    
    
      
    
    
      use the old - um,
    
    
      
    
    
      the - the - the old, uh,  segmentations, 
    
    
      Segmentation?
    
    
      then we'll just use that, I figure.
    
    
      Right.
    
    
      Um -
    
    
      S- So,
    
    
      um.
    
    
      I don't want you to have to be burdened with doing a lot of stuff. What - what can I do to - ?
    
    
      Y- y- you said it would be easy for you to do that  top one there, and  I guess Don can do the segmentations of the,
    
    
      uh, channel F_?
    
    
      Mm-hmm.
    
    
      Um -
    
    
      I mean, I can certainly help with, uh, retraining  the short male models,
    
    
      Right.
    
    
      uh, once we have the new data.
    
    
      You have models of short males?
    
    
      
    
    
      
    
    
      
    
    
      
    
    
      Yeah.
    
    
      
    
    
      Um -
    
    
      Right. Uh, let's see. The - the
    
    
       You - you can - I mean  you could -
    
    
      you could run the,
    
    
      um,
    
    
      you c- Basically, once
    
    
      the, um,
    
    
      The top one is done. I c-
    
    
      whe- the top - the top one's done, you could easily re-run the whole set of experiments.
    
    
      I can re-do the  next one. Yeah.
    
    
      Mm-hmm.
    
    
      Uh, I mean,
    
    
      manage the jobs and so forth, uh -
    
    
      Yeah. Sure.
    
    
      
    
    
      Um, that's all -
    
    
      Yeah, the -
    
    
      the bottom one would b- just be a matter of pointing it at a new set of files and kicking it off, so that would be re-
    
    
      I mean, th- not the  bottom  one, but the  middle  one 
    
    
      Mm-hmm.
    
    
      would be really easy once you've got the top one going. I could do that.
    
    
      Yeah.
    
    
      Right.
    
    
      O_K. So I guess I just need to
    
    
      get Don to,
    
    
      uh -
    
    
      Right. So, somehow the -
    
    
      
    
    
      Assuming he uses the new naming scheme, then
    
    
      he should call  the waveforms
    
    
      the - so, the waveform names have the, you know, meeting - meeting I_D,
    
    
      and the  microphone,
    
    
      and the,
    
    
      
    
    
      um -
    
    
      I guess, the channel and the microphone and the speaker,
    
    
      um,
    
    
      
    
    
      speaker - some- something that identifies the speaker.
    
    
      Mm-hmm.
    
    
       So -
    
    
      To keep it the same but j- just change them all to channel F_?
    
    
      Exactly. So, uh - well, you still need to be able to distinguish the different speakers.
    
    
      That's the key point. Because, if we wanna do what we just discussed - So -
    
    
      Right. Right.
    
    
      Yeah.
    
    
      
    
    
      Uh, uh, the - the best - the easiest way to do that would be to just take -
    
    
      You know, you make the channel be channel F_,
    
    
      but then keep the speaker names the same as they would be in the old -
    
    
      Yeah.
    
    
      O_K.
    
    
      O_K. 
    
    
      in the close-talking,
    
    
      uh,
    
    
      version.
    
    
      O_K. And so that's something that Don would do - right? - when he creates these.
    
    
      Right. Exactly.
    
    
      O_K. O_K.
    
    
      So will you talk to him about that, or do you want me to talk to him?
    
    
      I, uh, I - I can talk to him.
    
    
      O_K.
    
    
      
    
    
      And then the bottom  one in terms of the test will be - ?
    
    
      Uh -
    
    
      That will just be a copy of the one above it, except for  different models
    
    
      Well, we also have to mean subtract the test data.
    
    
      from training.
    
    
      
    
    
      Ah. O_K.
    
    
      So, we need to run - ?
    
    
      O_K.
    
    
      
    
    
      Well, once we have the new, uh -
    
    
      Well, once I do that, uh, second experiment, we'll have the,
    
    
      um,  files,  and I can give you those to - to process.
    
    
      O_K.
    
    
      And there's, um,
    
    
      
    
    
      S- so the way this means subtraction expects to work, is it expects
    
    
      to have, um,
    
    
      this continuous stream of audio data
    
    
      from a particular speaker to operate on. And it goes along it with this sliding window,
    
    
      calculating the mean using the data in the window,
    
    
      and then subtracting that.
    
    
      So, do you create this continuous stream from the individual utterance files?
    
    
      I mean, uh -
    
    
      That's - that's how I've been doing it, just by concatenating files together.
    
    
      Hmm.
    
    
      
    
    
      Um, and if these files - and the- since they're individual utterance files, um,
    
    
      s- long silence periods are removed, which is a  good  thing.
    
    
      Because this method might estimate the mean badly, if it had to face long silence periods.
    
    
      
    
    
      But that  does  mean that I need as much -
    
    
      I need  twice  as much disk space as the original set
    
    
       cuz I need - while I'm running it - cuz I need to create this intermediate set,
    
    
      um, of these  big  files,
    
    
      Yeah.
    
    
      Hmm. 
    
    
      and then  create the - finally, the mean subtracted, um, little files.
    
    
      And then I can get rid of the  big  files.
    
    
      But st- while I'm doing the processing, I'll nee- I need twice as much disk space.
    
    
      O_K. I'm gonna - I'll check with, um,
    
    
      Markham, and see what happened with the - the disks.
    
    
      He went to put those on a couple of weeks ago and something -
    
    
      I think  Markham's out on  vacation.
    
    
      I think, che- check with Dave. Yeah.
    
    
      Oh, O_K. I'll ask David, then.
    
    
      Yeah.
    
    
      You haven't seen new disks pop up, have you?
    
    
      Nope.
    
    
      I was wondering  if they were  in.
    
    
      O_K.
    
    
      Yeah.
    
    
      Well, they grow them on trees now.
    
    
      
    
    
      
    
    
      
    
    
      
    
    
       I thought they were like mushrooms.  They're popping up. 
    
    
      
    
    
      
    
    
      Well, he went to put  them   on -
    
    
      Just, you  shake  them and they fall down.
    
    
      Yeah.  
    
    
      
    
    
      
    
    
      
    
    
      He went to put  them   on and then something happened.
    
    
      
    
    
      Yeah.
    
    
      And he sent around a note saying "Oh, uh,
    
    
      Yeah. Something w- went wrong.
    
    
      it didn't work, and
    
    
      we'll have to schedule another time." And then,
    
    
      
    
    
      didn't see - nothing happened.
    
    
      Nothing happened. No? Yeah.
    
    
      So - 
    
    
      I'll check with David about that.
    
    
       O_K.  
    
    
      O_K.
    
    
      
    
    
      Yeah. 
    
    
      Cuz we still all have tha- the - that other one going, which is the, uh - the Macrophone
    
    
      Right, an- and -
    
    
      training. 
    
    
      So - so, Andreas, um,
    
    
      Mm-hmm?
    
    
      in U_ doctor speech data S_R_I Hub-five, there's this, uh, Hub-five training set. Now, is that the long training set there?
    
    
      Mmm.
    
    
      Mm-hmm.
    
    
      Mm-hmm.
    
    
      That's everything. Yeah, so - 
    
    
      O_K.
    
    
      So, I can give you a list of the short  version.
    
    
      O_K. I th- I think you already did, actually.
    
    
      So you can -
    
    
      Oh, O_K.
    
    
      
    
    
      O_K. And so, say the  Macrophone  files that are included in this short training, are just
    
    
      a  subset  of the Macrophone files. Right?
    
    
      That's right.
    
    
      O_K. So - so, um - when you - You did some T_I-digits t- t- experiments training on Macrophone.
    
    
      Yeah.
    
    
      Um.
    
    
      But that's not necessarily any  less  data  than the S_R_I Hub-five
    
    
      set. It's not a - it's not a  subset  of the  short  S_R_I Hu- Hub-five set. Right?
    
    
      Um -
    
    
      Wel- No, it is.
    
    
      Th- the -
    
    
      Sorry. Um.
    
    
      Can you repeat the question?  There wa- it is a subse- Yeah.
    
    
      
    
    
      
    
    
      Uh, whe- when you trained on Macrophone, um, to do those digits experiments, did you use the  entire  Macrophone corpus?
    
    
      No. Only the portion that was in the Hub-five training set.
    
    
      Oh. O_K.
    
    
      That was in the Hub-five  small  training set?
    
    
      Well, the Hub-five small training set contains
    
    
      as much Macrophone as the large training set,
    
    
      Yes.
    
    
      for historical reasons. Yeah.
    
    
      O_K- O_K. So -
    
    
      Um -
    
    
      So, do you have that processed there, then - right?
    
    
      Because you already did - did y- didn't you already do that experiment?
    
    
      I- 
    
    
      I - I got confused, cuz I thought - I thought you were using
    
    
      Mm-hmm.
    
    
       the whole Macrophone set.
    
    
      No.
    
    
      Um. O_K.
    
    
      Well, if - if - if I just need to use that subset, I - I can get it processed. I actually  got -
    
    
      I think I got f-
    
    
      into it before, and then I thought I was doing the wrong thing and I stopped. And it shouldn- it shouldn't take that long to do.
    
    
      Mmm.
    
    
      O_K.
    
    
       Right.
    
    
      O_K.
    
    
      And you need only the males. So.
    
    
      
    
    
      Oh, O_K. 
    
    
      
    
    
      So, basically, Dave, so y- for you to get your processing going, you need the list of the, uh, wave-
    
    
      Well, I guess it'll dep- you'll - you'll - we'll need to get the segmentations.
    
    
      Yeah.
    
    
      Figure out whether we're using the new or the old  from Don.
    
    
      Hmm.
    
    
      And then, uh,
    
    
      from that you need the - from the segmentations you'll have the list of
    
    
      wavefiles that the short,
    
    
      uh, set is trained on.
    
    
      And then 
    
    
      you'll need disk space. And once you've got   those  things, then you can start  your  processing. Right?
    
    
      Yeah.
    
    
      O_K.
    
    
      
    
    
      
    
    
      Does this - th- this - ?
    
    
      
    
    
      
    
    
      It- it's sort of - f- f-
    
    
      not very nice to use the small training set for another reason, which is that the
    
    
      
    
    
      you also are losing on -
    
    
      Again,
    
    
      because you don't use  all the data you have for one speaker.
    
    
      So, the normalizations you compute for your training speakers will be,
    
    
      uh, crummier  than they would in the large training set.
    
    
      
    
    
      So, 
    
    
      um, I have to - So, to make it really a  matching  experiment, I have to find -
    
    
       
    
    
      uh, I have to
    
    
      use short models that were trained on  normalizations  that were also only estimated on the  short
    
    
      set.
    
    
      Which is, uh -
    
    
      Do you have this, uh - ? 
    
    
       I  think  so. I've - I -
    
    
      I have to check. In any case, I could retrain short models within 
    
    
      a few hours actually at - if I use
    
    
      
    
    
      machines at S_R_I.
    
    
      I wonder about that, though.
    
    
      Hmm?
    
    
      I mean, because
    
    
       all  we're doing - The only reason we're using the short training set is - is for speed.
    
    
      And there - we're not really making any  claims  about using a smaller training set.
    
    
      Yeah.
    
    
      So as long as we're not using any testing data from -
    
    
      No. But the thing is, if - if we used -
    
    
      if we used the whole training set for normalizations,
    
    
      Yeah.
    
    
      then  David would have to process much more data,
    
    
      which - That's a - that's one bottleneck, for us right, in terms of get-
    
    
      Oh, you mean for - for  his  normalizations.
    
    
      Yeah.
    
    
      
    
    
      Oh, oh, oh. I'm sorry.
    
    
      Right.
    
    
      So, you wanna do the exact same thing, or else  you'll have apples and oranges. 
    
    
      Right.
    
    
      Yeah.
    
    
      So.
    
    
      
    
    
      It doesn't make - I don't think it makes  that  much of a difference. It's just this
    
    
      little detail that
    
    
      Mm-hmm. 
    
    
      if you can
    
    
      take care of that, then you should.
    
    
      I - I think I have - I have the models, I have - 
    
    
      
    
    
      I have, um -
    
    
      
    
    
      let's see, um - 
    
    
      Yeah. And if not I can retrain  those models very
    
    
      
    
    
      Oh, there's - there's one other issue,
    
    
      quickly.
    
    
      uh, and that is that Dave throws out
    
    
      speakers that have less than twelve seconds of training data.
    
    
      And he said there were a few in the Macrophone set like that.
    
    
      So, do we need to wait
    
    
      to find out who he's gonna throw out, so that we create
    
    
      a new set of short models that don't include those speakers?
    
    
      Uh -
    
    
      Say this again?
    
    
      Sorry I missed it. 
    
    
      So i- in -
    
    
      
    
    
      Th- the problem is that if we proceed like we just described,
    
    
      um, 
    
    
      when he goes to
    
    
      m- um, 
    
    
      create the new s- training  data with his processing, he throws out some speakers.
    
    
      So the t- two training sets won't be identical.
    
    
      Yeah.
    
    
      He throws out some speakers that are - that are very small.
    
    
      Yeah. Have just a little bit.
    
    
      Yeah. I don't think it'll make a - matter.
    
    
      Yeah. I think there was only a few
    
    
      O_K.
    
    
      we thought to be the case. Righ- ?
    
    
      In fact, I thought about throwing those out too, because
    
    
      when I heard how little speech there was for some of them, I thought they can only hurt your models, because they're -
    
    
      again their normalizations will be all -
    
    
      Yeah.
    
    
      Right.
    
    
      all - all over the map, and
    
    
      you won't get
    
    
      very - very clean
    
    
      models from them, anyhow. So.
    
    
      So you think it's O_K, then?
    
    
      Yeah. In fact,
    
    
      if - if you wanna do this, uh, to speed things up,
    
    
      um,
    
    
      you - we can leave out the Macrophone data altogether.
    
    
      That hurt -
    
    
      Actually. Oh, no. Sorry.
    
    
      Not in the short. Then you have too little data. O_K.
    
    
      Sorry. Forget that.
    
    
      Um,
    
    
      When you use - when you go to the large training set,
    
    
      then  leaving out Macrophone
    
    
      actually sometimes  helps  you, because it's -
    
    
      it- it's just not relevant to the -
    
    
      It's read.
    
    
      to the meeting and - or to  conversational  speech anyway.
    
    
       O_K.
    
    
      
    
    
      Yeah. Leave it out, and - 
    
    
      Um, in the event that I retrain the short models,
    
    
      um, why don't you give me a list of the files that you throw out, and I - I'll throw them out, too.
    
    
      Right.
    
    
      And then we have complete - 
    
    
      completely  identical training conditions.
    
    
      
    
    
      We sh-
    
    
      M- Right.
    
    
      A- actually you should be able to figure out,
    
    
      Dave, right, once you know the segmentations,
    
    
      Mm-hmm.
    
    
      uh, who you're going to -
    
    
      which speakers will get left out, even before you run your processing. Right?
    
    
      The segmentations?
    
    
      Yeah. The segmentations from Don?
    
    
      But th- the segmentations are only -
    
    
      Once we - ?
    
    
      Oh.
    
    
      they only affect the  test  set.
    
    
      We're talking about the  training  speakers.
    
    
      
    
    
      Ah. Right, right, right, right, right.
    
    
      No. The training set he could go through right now, and see how - how long the -
    
    
       Right.
    
    
      Right. But I'm just wondering how long it will take to get
    
    
      
    
    
      that information.
    
    
      Um - 
    
    
      He already has the in- you already have the information.  Right? 
    
    
      I - I have i- I have it for -
    
    
      for Macrophone, um,
    
    
      already, I  think,  and, um, I think by tomorrow I'll have it
    
    
      Mm-hmm.
    
    
      O_K.
    
    
      for th- for the rest.
    
    
      Alright.
    
    
      O_K.
    
    
      
    
    
       O_K.  
    
    
      At that one?  Maybe.
    
    
      Uh -
    
    
      Been looking at synthesizers?
    
    
      
    
    
      
    
    
      Synthesizers?
    
    
      You were looking at Festival. Yeah.
    
    
      Yeah, yeah. I was doing something for  the SmartKom data collectioners.
    
    
      
    
    
      Robert has taken his laptop t- back to Germany so we needed a new synthesis machine.
    
    
      And we have now a SUN workstation in the library,
    
    
      which does the synthesis and the Festival speech s- s- system is  running on   it. 
    
    
      
    
    
      Sorry, Robert did what?
    
    
      Robert took what?
    
    
      His laptop where, uh -
    
    
      which we used for the SmartKom data collection, for the synthesis.
    
    
      Uh-huh.
    
    
      And so he took it to Germany
    
    
      and  so we couldn't do any data collection. Uh -
    
    
      Oh.
    
    
      Is he gone now?
    
    
      No. He's just gone to a SmartKom workshop.
    
    
      Oh.
    
    
      Oh, oh. Oh, O_K.
    
    
      And so, we have now the SUN in the library which can do that.
    
    
      Ah.
    
    
      
    
    
      And I looked into the ts- F_zero thing and talked to -
    
    
      to Liz, and it seems that
    
    
      it's quite
    
    
      s-
    
    
      what she wants, but we'll
    
    
      
    
    
      have to think about the - the  energy   thing - uh, what we wanna do.
    
    
      Right.
    
    
      
    
    
      This was a business about, uh,
    
    
      um,
    
    
      coming up with something that - that was purely prosodic.
    
    
      Mm-hmm.
    
    
      And so, uh, we're just gonna
    
    
      use a pitch detector, drive a synthesizer, and
    
    
      since it doesn't have a hook in it for, uh, modifying energy, we'll have a little
    
    
      box at the output that'll modify the energy.
    
    
      So - 
    
    
      Hmm.
    
    
      
    
    
      Hmm.
    
    
      
    
    
      O_K. 
    
    
      
    
    
      So. Rrrrr-rrrrm-rr. 
    
    
      
    
    
      
    
    
      
    
    
      
    
    
      
    
    
      Something like that. 
    
    
      Are you - are you interfacing to that thing with the C_plus-plus routines?
    
    
      Or are you - is there another interface that you use?
    
    
      For w- for Festival?
    
    
      Yeah.
    
    
      Uh, you can just  use it from the - Yeah.
    
    
      Basically from the command line, and the- defining the phones, whatever you want to have synthesized, and
    
    
      Oh.
    
    
      
    
    
      And it saves it in a -
    
    
      give the F_zero targets, and then ts-
    
    
      get - gives out a - a waveform, and I - I want to manipulate the - the waveform, then.
    
    
      I see.
    
    
      Oh, that's neat.
    
    
      Hmm.
    
    
      
    
    
      O_K? 
    
    
      
    
    
      Digits?
    
    
      
    
    
      
    
    
      
    
    
      Ah. O_K.
    
    
      Transcript L_ dash two eight eight. 
    
    
      Five two three, eight one seven, seven one nine. 
    
    
      Four two three, one five, eight eight two three. 
    
    
      Seven six eight, six O_ eight, two two one two. 
    
    
      Six nine two six, nine, two four nine. 
    
    
      Five seven, three six, zero one, zero six, four five. 
    
    
      One three one, three three four, three nine eight. 
    
    
      One, six one two, six six, nine one one, eight. 
    
    
      Zero two two, six seven, six six five one. 
    
    
      Transcript L_ dash two nine zero. 
    
    
      Four two eight zero, two three one three, one three eight two. 
    
    
      Three, five two six, zero five, nine eight eight, one. 
    
    
      One five, eight five, nine nine, four one, five six. 
    
    
      Eight eight three, seven nine two, two seven two. 
    
    
      
    
    
      Three nine seven, three three three, two two six. 
    
    
      Zero zero six, three eight, zero three three one. 
    
    
      Eight three six three, four six four six, seven four seven three. 
    
    
      Five nine, two two, zero zero, eight two, seven nine. 
    
    
      Transcript L_ dash two eight zero. 
    
    
      Five three zero, four six, four four three eight. 
    
    
      Six three, eight four, nine eight, five zero, nine nine. 
    
    
      Three nine seven zero, nine zero nine three, five nine seven five. 
    
    
      Zero two one five, three one three three, eight one six six. 
    
    
      Nine seven four, eight four seven, nine seven three. 
    
    
      Two seven, four one, five nine, one two, six nine. 
    
    
      Two four, two five, five seven, one nine, zero zero. 
    
    
      Five one seven, three nine seven, zero six one eight. 
    
    
      Transcript L_ two eight one. 
    
    
      Zero four three one, eight zero seven eight, one four five nine. 
    
    
      Two nine seven, one four six, six two O_ four. 
    
    
      Zero three, six five, nine seven, six two, four seven. 
    
    
      
    
    
      Five two, one five, eight four, one one, six six. 
    
    
      Four six two one, four, six six four. 
    
    
      Nine four zero two, one two three three, two O_ seven three. 
    
    
      Nine, seven seven eight, zero four, seven two nine, five. 
    
    
      Three seven, eight seven, nine seven, three four, six six. 
    
    
      Transcript L_ dash two O_ eight. 
    
    
      
    
    
      Two nine two, two six, nine six three four. 
    
    
      Six, nine one seven, two nine, seven seven eight, two. 
    
    
      Two eight three, four nine one, two seven seven. 
    
    
      Four nine zero, eight six nine, six four three two. 
    
    
      Nine six six, seven zero, four nine four O_. 
    
    
      Six three eight seven, two eight two six, nine zero five nine. 
    
    
      One seven seven, five eight six, eight one four. 
    
    
      Five six six, six five, six eight O_ nine. 
    
    
      Transcript L_ dash two eight seven. 
    
    
      One eight three, eight eight eight, eight one five five. 
    
    
      Two three, zero nine, three three, six one, zero nine. 
    
    
      Three six, eight five, one zero, three four, five two. 
    
    
      One one, four three, nine three, six seven, zero two. 
    
    
      One five seven one, zero zero seven two, eight eight nine six. 
    
    
      Two two four six, five, nine one three. 
    
    
      Zero seven two one, four, five nine eight. 
    
    
      Six, four five four, one one, six three three, six. 
    
    
      That's all folks.
    

  


