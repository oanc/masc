/*
 * The "classic" Goldfish example from the Gate documentation.
 *
 * Runs the ANNIE tokenizer and sentece splitter, annotate all occurences
 * of the word "goldfish" and saves the generated annotations to a serial
 * datastore.
 *
 * USAGE
 *
 * grate goldfish.gr8 <directory_of_files> <datastore_directory>
 *
 */
 
import gate.*
import gate.creole.*
import gate.creole.metadata.*
import org.anc.io.SuffixFilter

// Check the command line parameters.
File indir = new File(this.args[0])
if (!indir.exists())
{
	println "Input directory not found."
	return
}
if (!indir.isDirectory())
{
	println "Specified input is not a directory"
	return	
}

File outdir = new File(this.args[1])
if (!outdir.exists())
{
	println "Datastore directory does not exist."
	return
}
if (!outdir.isDirectory())
{
	println "Datastore location is not a directory."
	return
}

// A file filter that accepts only text files.
def filter = new FileFilter() {
	public boolean accept(File file)
	{
		return !file.isDirectory() && file.name.endsWith('.txt')
	}
}

/*
 * GATE Processing Resource definitions.
 */
 
// EchoResource simple echoes the document source URL to System.out.
@CreoleResource
class EchoResource extends gate.creole.AbstractLanguageAnalyser
{
	void execute()
	{
		println "Processing ${document.sourceUrl}"
	}
}

// The Goldfish annotator.  Adds a "Goldfish" annotation to every occurence
// of the word Goldfish in a document.  This PR is case-sensitive.
@CreoleResource
class GoldfishAnnotator extends gate.creole.AbstractLanguageAnalyser {
	static final String TOKEN = ANNIEConstants.TOKEN_ANNOTATION_TYPE
	static final String SENTENCE = ANNIEConstants.SENTENCE_ANNOTATION_TYPE
	static final String KIND = ANNIEConstants.TOKEN_KIND_FEATURE_NAME
	static final String STRING = ANNIEConstants.TOKEN_STRING_FEATURE_NAME
	
	// The name of the input gate.AnnotationSet
	String inputASName
	// The name of the output gate.AnnotationSet
	String outputASName
	
	void execute() {
		int total = 0
		def inputAS = inputASName ? document.getAnnotations(inputASName) : document.getAnnotations()
		def outputAS = outputASName ? document.getAnnotations(outputASName) : document.getAnnotations()
		
		def tokens = inputAS.get(TOKEN)
		def sentences = inputAS.get(SENTENCE)
		
		document.features.clear()
		document.features.put('Number of tokens', tokens.size())
		document.features.put('Number of characters', document.content.toString().length())
		document.features.put('Number of sentences', sentences.size())

		int wordCount = 0
		sentences.each { s ->
			int sentenceGoldfishCount = 0
			tokens = inputAS.get(TOKEN, s.startNode.offset, s.endNode.offset)
			tokens.each { token ->
				if (token.features[KIND]  == 'word') {
					++wordCount
					String word = token.features[STRING]
					if (word == 'Goldfish') {
						++sentenceGoldfishCount
						outputAS.add(token.startNode.offset, token.endNode.offset, 'Goldfish', Factory.newFeatureMap())
					}					
				}
			}
			total += sentenceGoldfishCount
			s.features['Goldfish count'] = sentenceGoldfishCount
		}
		document.features['Number of words'] = wordCount
	}
}

// The ANNIE tokeniser.
def tokenizer = newResource('gate.creole.tokeniser.DefaultTokeniser') {
	annotationSetName('Annie')
}

// The ANNIE sentence splitter.
def splitter = newResource('gate.creole.splitter.SentenceSplitter') {
	inputASName('Annie')
	outputASName('Annie')
}

println "Populating the corpus"
def corpus = newCorpus('Transient corpus') {
	indir.listFiles(filter).each { file ->
		addDocument(file)
	}
}

def register = Gate.getCreoleRegister()
register.registerComponent(GoldfishAnnotator)
register.registerComponent(EchoResource)

def goldfishPR = new GoldfishAnnotator()
goldfishPR.inputASName = 'Annie'
goldfishPR.outputASName = 'Goldfish'

def echoPR = new EchoResource()

println "Setting up pipeline."
def pipeline = newResource('gate.creole.SerialAnalyserController') { }
pipeline.setCorpus(corpus)
pipeline.add(echoPR)
pipeline.add(tokenizer)
pipeline.add(splitter)
pipeline.add(goldfishPR)

println "Running pipeline."
pipeline.execute()

println "Serializing the corpus."
def dsDir = new File('D:/Temp/GoldfishDS')
def store = newSerialDataStore(dsDir)
def persisted = store.adopt(corpus, null)
store.sync(persisted)
println "Done."
